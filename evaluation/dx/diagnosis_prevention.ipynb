{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from utilities.preprocess import train_valid_test_split, preprocess_patient_state_tuples, pad_int_icd\n",
    "from utilities.utils import load_json\n",
    "from utilities.model import BertDxModel, encoder_names_mapping\n",
    "\n",
    "from diagnosis_classifier import DiagnosisClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_diff_subset(target: str, data: list, in_icds: list, out_icds: list) -> list:\n",
    "    assert len(data) == len(in_icds) == len(out_icds)\n",
    "    subset = list()\n",
    "    subset_labels = list()\n",
    "    for sample, in_icd, out_icd in zip(data, in_icds, out_icds):\n",
    "        if target == \"all\":\n",
    "            if in_icd != out_icd:\n",
    "                subset.append(sample)\n",
    "                subset_labels.append(out_icd)\n",
    "        else:\n",
    "            if (in_icd != out_icd) and (out_icd == target):\n",
    "                subset.append(sample)\n",
    "                subset_labels.append(out_icd)\n",
    "\n",
    "    return subset, subset_labels\n",
    "\n",
    "def make_incremental_docs(patient_states: List[List[Tuple[str, int]]], label2token: Dict[int, str]) -> List[List[str]]:\n",
    "    docs = list()\n",
    "    for patient_state in patient_states:\n",
    "        subdocs = list()\n",
    "        for i in range(len(patient_state)):\n",
    "            sub_patient_state = patient_state[:i + 1]\n",
    "            subdoc = preprocess_patient_state_tuples([sub_patient_state], label2token=label2token)[0]\n",
    "            subdocs.append(subdoc)\n",
    "        docs.append(subdocs)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "def eval_dx_reminder(dx_classifier: DiagnosisClassifier, docs: List[List[str]], labels: List[str], hit_k: int) -> Tuple[float, float]:\n",
    "    assert len(docs) == len(labels)\n",
    "    earliest_hits = [1] * len(labels)\n",
    "    incremental_hits = [0] * len(labels)\n",
    "    for i in tqdm(range(len(labels))):\n",
    "        subdocs = docs[i]\n",
    "        label = labels[i]\n",
    "\n",
    "        all_logits = dx_classifier.predict(subdocs)\n",
    "        dxs_l, _ = dx_classifier.get_top_dxs_with_probs(all_logits, top_k=hit_k)\n",
    "        for j, dxs in enumerate(dxs_l):\n",
    "            if label in dxs:\n",
    "                if earliest_hits[i] == 1:\n",
    "                    earliest_hits[i] = (j + 1) / len(subdocs)\n",
    "                incremental_hits[i] += 1 / len(subdocs)\n",
    "\n",
    "    mean_earliest_hit = sum(earliest_hits) / len(earliest_hits)\n",
    "    mean_incremental_hit = sum(incremental_hits) / len(incremental_hits)\n",
    "    return mean_earliest_hit, mean_incremental_hit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    full_emr_path=\"../../datasets/notes_B_full.json\",\n",
    "    unnorm_states_path=\"../../datasets/notes_B_unnorm.json\",\n",
    "    norm_states_path=\"../../datasets/notes_B_norm.json\",\n",
    "    in_icds_path=\"../../datasets/in_icds.json\",\n",
    "    out_icds_path=\"../../datasets/out_icds.json\",\n",
    "    \n",
    "    ner_model_path=\"../../models/ner\",\n",
    "    dx_model_path=\"../../training/dx/models_increment/encoder-BioLinkBERT__optimizer-AdamW__scheduler-linear__lr-5e-05__n_partials-4__input_type-norm__label_type-outicd__scheme-everyk\",\n",
    "    target_metric=\"micro_f1\",\n",
    "    batch_size=16,\n",
    "\n",
    "    seed=7,\n",
    "    train_size=0.8,\n",
    "    valid_size=0.1,\n",
    "    test_size=0.1,\n",
    "\n",
    "    device=\"cuda:1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "text_l = load_json(args.full_emr_path)\n",
    "norm_states = load_json(args.norm_states_path)\n",
    "in_icds = load_json(args.in_icds_path)\n",
    "out_icds = load_json(args.out_icds_path)\n",
    "\n",
    "id2icd = load_json(Path(args.dx_model_path) / \"id2icd.json\")\n",
    "icd2id = {pad_int_icd(icd): int(id_) for id_, icd in id2icd.items()}\n",
    "labels = [icd2id[icd] for icd in out_icds]\n",
    "\n",
    "# split data\n",
    "train_inputs, valid_inputs, test_inputs, train_outs, valid_outs, test_outs = train_valid_test_split(\n",
    "    inputs=norm_states,\n",
    "    labels=out_icds,\n",
    "    train_size=args.train_size,\n",
    "    valid_size=args.valid_size,\n",
    "    test_size=args.valid_size,\n",
    "    seed=args.seed\n",
    ")\n",
    "\n",
    "train_ins, valid_ins, test_ins, _, _, _ = train_valid_test_split(\n",
    "    inputs=in_icds,\n",
    "    labels=out_icds,\n",
    "    train_size=args.train_size,\n",
    "    valid_size=args.valid_size,\n",
    "    test_size=args.valid_size,\n",
    "    seed=args.seed\n",
    ")\n",
    "\n",
    "# get subset\n",
    "train_diff_set, train_diff_labels = get_disease_diff_subset(target=\"all\", data=train_inputs, in_icds=train_ins, out_icds=train_outs)\n",
    "valid_diff_set, valid_diff_labels = get_disease_diff_subset(target=\"all\", data=valid_inputs, in_icds=valid_ins, out_icds=valid_outs)\n",
    "test_diff_set, test_diff_labels = get_disease_diff_subset(target=\"all\", data=test_inputs, in_icds=test_ins, out_icds=test_outs)\n",
    "\n",
    "# make incremental documents\n",
    "test_incremental_docs = make_incremental_docs(patient_states=test_diff_set, label2token={0: \"positive\", 1: \"negative\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx_model = BertDxModel(encoder_name=encoder_names_mapping[\"BioLinkBERT\"], num_dxs=len(Counter(out_icds)))\n",
    "dx_model.load_state_dict(torch.load(Path(args.dx_model_path) / \"best_models\" / f\"best_{args.target_metric}.pth\"))\n",
    "dx_tokenizer = AutoTokenizer.from_pretrained(Path(args.ner_model_path) / \"tokenizer\", use_fast=True)\n",
    "id2dx = load_json(Path(args.dx_model_path) / \"id2icd.json\")\n",
    "dx2name = load_json(Path(\"../../models/dx\") / \"icdnine2name_en.json\")\n",
    "\n",
    "dx_classifier = DiagnosisClassifier(\n",
    "    model=dx_model,\n",
    "    tokenizer=dx_tokenizer,\n",
    "    id2dx=id2dx,\n",
    "    dx2name=dx2name,\n",
    "    batch_size=args.batch_size,\n",
    "    device=args.device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outs2count = Counter(test_outs)\n",
    "target_dxs = [\n",
    "    \"486\", # pneumonia\n",
    "    \"428\", # heart failure\n",
    "    \"590\" # pyelonephritis\n",
    "]\n",
    "target_hitks = [3, 5, 8]\n",
    "\n",
    "for target_dx in target_dxs:\n",
    "    print(f\"Evaluating target diagnosis {target_dx} - {dx_classifier.dx2name[target_dx] if target_dx in dx_classifier.dx2name else 'all'}\")\n",
    "    test_diff_set, test_diff_labels = get_disease_diff_subset(target=target_dx, data=test_inputs, in_icds=test_ins, out_icds=test_outs)\n",
    "    test_incremental_docs = make_incremental_docs(patient_states=test_diff_set, label2token={0: \"positive\", 1: \"negative\"})\n",
    "    print(f\"Number of samples: diff = {len(test_diff_labels)} (all = {test_outs2count[target_dx]})\")\n",
    "    for hitk in target_hitks:\n",
    "        print(f\"Evaluating hit@{hitk}...\")\n",
    "        earliest_hit, incremental_hit = eval_dx_reminder(dx_classifier, docs=test_incremental_docs, labels=test_diff_labels, hit_k=hitk)\n",
    "        print(f\"Mean earliest hit = {earliest_hit}; Mean incremental hit = {incremental_hit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda-11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b66dd0c8f752918e1728d86abaa8fb004a7dee1d90779ea4d0023d852f9fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
