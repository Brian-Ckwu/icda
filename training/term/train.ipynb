{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import fisher_exact\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utilities.utils import load_json, save_json\n",
    "from utilities.term import build_cooccurrence_matrix, build_fisher_matrix, build_term_ids_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "train_size = 0.8\n",
    "min_ndoc = 3\n",
    "threshold = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_states = load_json(\"../../datasets/norm_patient_states_t.json\")\n",
    "out_icds = load_json(\"../../datasets/out_icds.json\")\n",
    "cui2name = load_json(\"../../models/nen/smcui2name.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data, using only training data to make term lists\n",
    "train_X, eval_X, train_y, eval_y = train_test_split(\n",
    "    norm_states, \n",
    "    out_icds, \n",
    "    train_size=train_size, \n",
    "    test_size=(1.0 - train_size), \n",
    "    random_state=seed, \n",
    "    stratify=out_icds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data for building the cooccurrence matrix\n",
    "entities_l = list()\n",
    "for norm_state in train_X:\n",
    "    entities = set()\n",
    "    for entity, pol in norm_state:\n",
    "        entities.add(entity)\n",
    "    entities_l.append(entities)\n",
    "\n",
    "labels = train_y\n",
    "\n",
    "vocab = {name: i for i, (cui, name) in enumerate(cui2name.items())}\n",
    "save_json(obj=vocab, f=\"./term2id.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Co-occurence Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_matrix = build_cooccurrence_matrix(entities_l, labels, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Term-Label Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2ndoc = Counter(labels)\n",
    "total_ndoc = len(train_y)\n",
    "f_matrix = build_fisher_matrix(co_matrix, label2ndoc, total_ndoc, min_ndoc=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_matrix.to_csv(\"./fisher_matrix.csv\", index_label=\"term_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_matrix = pd.read_csv(\"./fisher_matrix.csv\", index_col=\"term_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Term Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build term_ids lists\n",
    "term_ids_lists = build_term_ids_lists(score_matrix=f_matrix, mode=\"lesser\", threshold=threshold)\n",
    "\n",
    "# convert term_ids to terms\n",
    "id2term = {v: k for k, v in vocab.items()}\n",
    "terms_lists = dict()\n",
    "\n",
    "for label, term_ids in term_ids_lists.items():\n",
    "    terms = list(map(lambda term_id: id2term[term_id], term_ids))\n",
    "    terms_lists[label] = terms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cuda-11.3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35b66dd0c8f752918e1728d86abaa8fb004a7dee1d90779ea4d0023d852f9fe7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
